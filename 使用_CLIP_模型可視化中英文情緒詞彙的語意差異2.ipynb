{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuXj0O46xhHpicg4AOqQpH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shimo23333/generative_ai/blob/main/%E4%BD%BF%E7%94%A8_CLIP_%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A6%96%E5%8C%96%E4%B8%AD%E8%8B%B1%E6%96%87%E6%83%85%E7%B7%92%E8%A9%9E%E5%BD%99%E7%9A%84%E8%AA%9E%E6%84%8F%E5%B7%AE%E7%95%B02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLIP 多語言情緒詞 → 圖像 → 色票分析"
      ],
      "metadata": {
        "id": "3c3H40bwD6Q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.安裝必要套件\n",
        "先安裝會用到的四個核心工具，CLIP 負責語意處理、colorthief 負責從圖像擷取主色、googletrans 用來翻譯情緒詞，OpenCV 把 RGB 轉成 Lab 色彩空間。"
      ],
      "metadata": {
        "id": "1hhL_zhf0B0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 1：安裝必要套件\n",
        "!pip install git+https://github.com/openai/CLIP.git # 安裝 OpenAI 的 CLIP 模型\n",
        "!pip install colorthief # 安裝色票擷取套件\n",
        "!pip install googletrans==4.0.0-rc1 # 安裝 Google 翻譯 API 套件\n",
        "!pip install opencv-python # 安裝 OpenCV，進行色彩轉換"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V1yf47-4z2pV",
        "outputId": "df96c327-68d3-45db-9c16-39183f4a45b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-zlxmx6lu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-zlxmx6lu\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Requirement already satisfied: colorthief in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from colorthief) (11.2.1)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.11/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.11/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.4.26)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.引入套件\n",
        "把所有需要用到的 Python 套件載入，並且為了圖表美觀，設定可以顯示中文字的字體。"
      ],
      "metadata": {
        "id": "8sVoP32Z3ZS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "898JT3xGzVhf"
      },
      "outputs": [],
      "source": [
        "# 區塊 2：引入套件\n",
        "import clip\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "from colorthief import ColorThief\n",
        "from googletrans import Translator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "\n",
        "# 設定中文字體（避免亂碼）\n",
        "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.初始化 CLIP 與翻譯工具\n",
        "這裡載入 CLIP 模型，選用 ViT-B/32 版本。如果使用者有 GPU 就用 CUDA，沒有就用 CPU。翻譯器 Translator 用來翻多語情緒詞。"
      ],
      "metadata": {
        "id": "IIMorOTz3gur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 3：設定模型與語言\n",
        "translator = Translator()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n"
      ],
      "metadata": {
        "id": "s7diBVqB3hmW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4：翻譯原始情緒詞（中文 → 英、日、韓）\n",
        "定義一組情緒詞，並透過 Google 翻譯 API，自動翻成英文、日文、韓文。這樣每個中文情緒詞就會對應四種語言版本。"
      ],
      "metadata": {
        "id": "7eEuNMNfFnw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 4：輸入原始中文詞 → 翻譯為中英日韓\n",
        "emotion_words_zh = [\"溫暖\", \"空虛\", \"混亂\", \"壓抑\", \"從容\", \"曖昧\"]\n",
        "def translate_words(words):\n",
        "    results = []\n",
        "    for word in words:\n",
        "        en = translator.translate(word, src='zh-CN', dest='en').text\n",
        "        ja = translator.translate(word, src='zh-CN', dest='ja').text\n",
        "        ko = translator.translate(word, src='zh-CN', dest='ko').text\n",
        "        results.append({\"zh\": word, \"en\": en, \"ja\": ja, \"ko\": ko})\n",
        "    return results\n",
        "\n",
        "translated_emotions = translate_words(emotion_words_zh)"
      ],
      "metadata": {
        "id": "HO_ZOrLYEUlm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5：用 CLIP 提取語意圖像\n",
        "理想上這裡可以搭配 DALL·E 做語意生成，但這個版本使用 Unsplash 隨機抓對應詞的圖片來模擬圖像回傳（像是搜尋「warm」就可能抓到夕陽圖片）。"
      ],
      "metadata": {
        "id": "t_r0TgC1Ftfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 5：從 CLIP 擷取語意圖像\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "\n",
        "def retrieve_image(text, lang):\n",
        "    prompt = f\"{text}\"\n",
        "    with torch.no_grad():\n",
        "        text_token = clip.tokenize([prompt]).to(device)\n",
        "        text_embed = model.encode_text(text_token)\n",
        "    # 模擬取得圖像（如有 DALL-E 可替換這裡）\n",
        "    url = f\"https://source.unsplash.com/400x400/?{text}\"\n",
        "    response = requests.get(url)\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    return image"
      ],
      "metadata": {
        "id": "Wvw9x4AcEYxe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6：從圖像中抓出主色（RGB）\n",
        "用 ColorThief 擷取圖片的主色（即色票中最顯眼的一個 RGB 值），這是我們後面做色彩分析的關鍵。"
      ],
      "metadata": {
        "id": "ddYj4OvdFvJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 6：色票分析 (使用 colorthief)\n",
        "def get_main_color(image):\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=\"PNG\")\n",
        "    buffer.seek(0)\n",
        "    color_thief = ColorThief(buffer)\n",
        "    dominant = color_thief.get_color(quality=1)\n",
        "    return dominant\n"
      ],
      "metadata": {
        "id": "2wJHkTleEaGG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7：RGB → Lab，並畫出顏色\n",
        "rgb_to_lab()：把 RGB 轉成 Lab 色彩空間，利於做數值比較。\n",
        "\n",
        "plot_colors()：將每種語言的主色畫出色票對照圖，一眼看出色彩差異。"
      ],
      "metadata": {
        "id": "mXyzIz_vFv_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 7：色彩轉 Lab (並視覺化)\n",
        "def rgb_to_lab(color):\n",
        "    rgb = np.uint8([[color]])\n",
        "    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
        "    return lab[0][0]\n",
        "\n",
        "def plot_colors(title, color_dict):\n",
        "    fig, ax = plt.subplots(1, len(color_dict), figsize=(10, 3))\n",
        "    for i, (label, rgb) in enumerate(color_dict.items()):\n",
        "        ax[i].imshow([[rgb]], aspect='auto')\n",
        "        ax[i].set_title(label)\n",
        "        ax[i].axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "t7Vx_ciFEbpo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8：主流程（翻譯 → 抓圖 → 擷取色彩 → 顯示）\n",
        "這是主要執行區塊，對每個情緒詞（如「溫暖」）跑一次完整流程：\n",
        "\n",
        "翻譯多語詞彙\n",
        "\n",
        "擷取對應圖片\n",
        "\n",
        "擷取主色\n",
        "\n",
        "畫出四個語言版本的色彩對照圖"
      ],
      "metadata": {
        "id": "yilxUKpzFwov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 區塊 8：主執行邏輯：逐一詞語 → 多語翻譯 → 生成圖像 → 色票 → 色彩對照圖\n",
        "for item in translated_emotions:\n",
        "    color_map = {}\n",
        "    for lang in [\"zh\", \"en\", \"ja\", \"ko\"]:\n",
        "        word = item[lang]\n",
        "        img = retrieve_image(word, lang)\n",
        "        rgb = get_main_color(img)\n",
        "        lab = rgb_to_lab(rgb)\n",
        "        color_map[f\"{lang}: {word}\"] = rgb\n",
        "    plot_colors(f\"『{item['zh']}』的多語色票對照\", color_map)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "7esofzuoEcWm",
        "outputId": "c95706fe-51ca-464e-c2f0-e2904d6c3977"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x7a74127bfbf0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-933f757bc713>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"zh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ja\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ko\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_main_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_to_lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-9fc419529a93>\u001b[0m in \u001b[0;36mretrieve_image\u001b[0;34m(text, lang)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://source.unsplash.com/400x400/?{text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3570\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7a74127bfbf0>"
          ]
        }
      ]
    }
  ]
}